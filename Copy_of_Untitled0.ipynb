{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNKwcu9iOp1uOKOiKrzXe1u",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shobha99-99/project2/blob/main/Copy_of_Untitled0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8TOSA7iogAW",
        "outputId": "e8263908-6a4c-4867-b500-03911bfc1b94"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.25.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.2.2)\n",
            "Collecting surprise\n",
            "  Downloading surprise-0.1-py2.py3-none-any.whl (1.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.11.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n",
            "Collecting scikit-surprise (from surprise)\n",
            "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.4/154.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
            "Building wheels for collected packages: scikit-surprise\n"
          ]
        }
      ],
      "source": [
        "!pip install numpy pandas scikit-learn surprise\n",
        "import pandas as pd\n",
        "from surprise import Dataset, Reader\n",
        "from surprise.model_selection import train_test_split\n",
        "from surprise import SVD\n",
        "from surprise import accuracy\n",
        "\n",
        "# Load the dataset (MovieLens 100k dataset)\n",
        "!wget -nc http://files.grouplens.org/datasets/movielens/ml-100k.zip\n",
        "!unzip -n ml-100k.zip\n",
        "\n",
        "ratings = pd.read_csv('ml-100k/u.data', sep='\\t', names=['user_id', 'movie_id', 'rating', 'timestamp'])\n",
        "# Define a Reader object with the expected format of the dataset\n",
        "reader = Reader(rating_scale=(1, 5))\n",
        "\n",
        "# Load the dataset into Surprise\n",
        "data = Dataset.load_from_df(ratings[['user_id', 'movie_id', 'rating']], reader)\n",
        "# Split the data into training and test sets\n",
        "trainset, testset = train_test_split(data, test_size=0.25)\n",
        "# Use the SVD algorithm for training\n",
        "algo = SVD()\n",
        "\n",
        "# Train the algorithm on the training set\n",
        "algo.fit(trainset)\n",
        "# Predict ratings for the test set\n",
        "predictions = algo.test(testset)\n",
        "\n",
        "# Calculate and print RMSE (Root Mean Squared Error)\n",
        "rmse = accuracy.rmse(predictions)\n",
        "print(f\"RMSE: {rmse}\")\n",
        "def get_top_n_recommendations(predictions, n=10):\n",
        "    from collections import defaultdict\n",
        "\n",
        "    # First map the predictions to each user.\n",
        "    top_n = defaultdict(list)\n",
        "    for uid, iid, true_r, est, _ in predictions:\n",
        "        top_n[uid].append((iid, est))\n",
        "\n",
        "    # Then sort the predictions for each user and retrieve the n highest ones.\n",
        "    for uid, user_ratings in top_n.items():\n",
        "        user_ratings.sort(key=lambda x: x[1], reverse=True)\n",
        "        top_n[uid] = user_ratings[:n]\n",
        "\n",
        "    return top_n\n",
        "\n",
        "# Generate recommendations for all users\n",
        "top_n_recommendations = get_top_n_recommendations(predictions, n=10)\n",
        "\n",
        "# Print the top 10 recommendations for a specific user (user_id = 1)\n",
        "user_id = 1\n",
        "print(f\"Top 10 recommendations for user {user_id}:\")\n",
        "for movie_id, predicted_rating in top_n_recommendations[user_id]:\n",
        "    print(f\"Movie ID: {movie_id}, Predicted Rating: {predicted_rating}\")\n"
      ]
    }
  ]
}